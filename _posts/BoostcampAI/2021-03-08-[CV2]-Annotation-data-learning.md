---
title: "[CV2] Annotation data efficient learning"
subtitle: 
tags: [data augmentation, knowledge distillation, transfer learning, semi-supervised learning, self-training] 

---

Boostcamp Day 31. 2021-03-08.
DAY31 TIL

# [Computer Vision] - Annotation data efficient learning

### Contents


## Intro
컴퓨터 비전 문제를 푸는 딥러닝 모델은 supervised learning으로 학습하는 것이 유리하다는 사실은 알려져 있습니다.
하지만, 딥러닝 모델을 학습할 수 있을 만큼 고품질의 데이터를 많이 확보하는 것은 보통 불가능하거나 그 비용이 매우 큽니다.

2강에서는 Data Augmentation, Knowledge Distillation, Transfer learning, Learning without Forgetting, Semi-supervised learning 및 Self-training 등 주어진 데이터셋의 분포를 실제 데이터 분포와 최대한 유사하게 만들거나,
이미 학습된 정보를 이용해 새 데이터셋에 대해 보다 잘 학습하거나,
label이 없는 데이터셋까지 이용해 학습하는 등 주어진 데이터셋을 최대한 효율적으로 이용해 딥러닝 모델을 학습하는 방법을 소개합니다.


## Further Reading
- [CutMix : ](https://arxiv.org/pdf/1409.1556.pdf)

## Reference

- bootcamp AI Tech pdf.  
- NAVER Connect Foundation.

